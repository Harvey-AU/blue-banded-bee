package db

import (
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"net/url"
	"os"
	"strings"
	"time"

	"github.com/Harvey-AU/blue-banded-bee/internal/cache"

	_ "github.com/jackc/pgx/v5/stdlib"
	"github.com/rs/zerolog/log"
)

// DB represents a PostgreSQL database connection
type DB struct {
	client *sql.DB
	config *Config
	Cache  *cache.InMemoryCache
}

// GetConfig returns the original DB connection settings
func (d *DB) GetConfig() *Config {
	return d.config
}

// Config holds PostgreSQL connection configuration
type Config struct {
	Host            string        // Database host
	Port            string        // Database port
	User            string        // Database user
	Password        string        // Database password
	Database        string        // Database name
	SSLMode         string        // SSL mode (disable, require, verify-ca, verify-full)
	MaxIdleConns    int           // Maximum number of idle connections
	MaxOpenConns    int           // Maximum number of open connections
	MaxLifetime     time.Duration // Maximum lifetime of a connection
	DatabaseURL     string        // Original DATABASE_URL if used
	ApplicationName string        // Identifier for this application instance
}

func poolLimitsForEnv(appEnv string) (maxOpen, maxIdle int) {
	switch appEnv {
	case "production":
		return 70, 20
	case "staging":
		return 5, 2
	default:
		return 2, 1
	}
}

func sanitiseAppName(name string) string {
	name = strings.TrimSpace(name)
	if name == "" {
		return ""
	}

	var builder strings.Builder
	builder.Grow(len(name))
	for _, r := range name {
		switch {
		case r >= 'a' && r <= 'z',
			r >= 'A' && r <= 'Z',
			r >= '0' && r <= '9',
			r == '-', r == '_', r == ':', r == '.':
			builder.WriteRune(r)
		default:
			// Skip unsupported characters to keep connection strings safe
		}
	}

	result := builder.String()
	if result == "" {
		return ""
	}
	return result
}

func trimAppName(name string) string {
	const maxLen = 60 // postgres application_name limit is 64 bytes
	if len(name) <= maxLen {
		return name
	}
	return name[:maxLen]
}

func determineApplicationName() string {
	if override := sanitiseAppName(os.Getenv("DB_APP_NAME")); override != "" {
		return trimAppName(override)
	}

	base := "bbb"
	if env := sanitiseAppName(strings.ToLower(strings.TrimSpace(os.Getenv("APP_ENV")))); env != "" {
		base = fmt.Sprintf("bbb-%s", env)
	}

	var parts []string
	if machineID := sanitiseAppName(os.Getenv("FLY_MACHINE_ID")); machineID != "" {
		parts = append(parts, machineID)
	}
	if host, err := os.Hostname(); err == nil {
		if hostName := sanitiseAppName(host); hostName != "" {
			parts = append(parts, hostName)
		}
	}
	parts = append(parts, time.Now().UTC().Format("20060102T150405"))

	if len(parts) == 0 {
		return trimAppName(base)
	}

	return trimAppName(fmt.Sprintf("%s:%s", base, strings.Join(parts, ":")))
}

func addConnSetting(connStr, key, value string) (string, bool) {
	if key == "" || value == "" {
		return connStr, false
	}

	trimmed := strings.TrimSpace(connStr)
	if trimmed == "" {
		return connStr, false
	}

	if strings.Contains(trimmed, key+"=") {
		return trimmed, false
	}

	isURL := strings.HasPrefix(trimmed, "postgres://") || strings.HasPrefix(trimmed, "postgresql://")

	if isURL {
		parsed, err := url.Parse(trimmed)
		if err == nil {
			q := parsed.Query()
			if q.Get(key) != "" {
				return trimmed, false
			}
			q.Set(key, value)
			parsed.RawQuery = q.Encode()
			return parsed.String(), true
		}

		separator := "?"
		if strings.Contains(trimmed, "?") {
			separator = "&"
		}
		return trimmed + separator + key + "=" + url.QueryEscape(value), true
	}

	escaped := strings.ReplaceAll(value, "'", "")
	if escaped == "" {
		return trimmed, false
	}
	return trimmed + fmt.Sprintf(" %s=%s", key, escaped), true
}

func cleanupAppConnections(ctx context.Context, client *sql.DB, appName string) {
	if client == nil || appName == "" {
		return
	}

	base := appName
	if idx := strings.Index(base, ":"); idx != -1 {
		base = base[:idx]
	}
	if base == "" {
		return
	}

	pattern := base + ":%"
	if base == appName {
		pattern = base
	}

	cleanupCtx, cancel := context.WithTimeout(ctx, 5*time.Second)
	defer cancel()

	query := `
		SELECT COALESCE(SUM(CASE WHEN pg_terminate_backend(pid) THEN 1 ELSE 0 END), 0)
		FROM pg_stat_activity
		WHERE pid != pg_backend_pid()
		  AND usename = current_user
		  AND state = 'idle'
		  AND application_name LIKE $1
		  AND application_name <> $2
	`

	var terminated int64
	if err := client.QueryRowContext(cleanupCtx, query, pattern, appName).Scan(&terminated); err != nil {
		log.Warn().Err(err).Msg("Failed to terminate stale PostgreSQL connections for application")
		return
	}

	if terminated > 0 {
		log.Info().
			Str("application_name", appName).
			Int64("terminated_connections", terminated).
			Msg("Terminated stale PostgreSQL connections from previous deployment")
	} else {
		log.Debug().
			Str("application_name", appName).
			Msg("No stale PostgreSQL connections found for termination")
	}
}

// ConnectionString returns the PostgreSQL connection string
func (c *Config) ConnectionString() string {
	connStr := strings.TrimSpace(c.DatabaseURL)
	if connStr != "" {
		connStr, _ = addConnSetting(connStr, "idle_in_transaction_session_timeout", "30000")
		connStr, _ = addConnSetting(connStr, "statement_timeout", "60000")
		if strings.Contains(connStr, "pooler.supabase.com") {
			if newStr, added := addConnSetting(connStr, "default_query_exec_mode", "simple_protocol"); added {
				log.Info().Msg("Added minimal prepared statement disabling for pooler connection")
				connStr = newStr
			} else {
				connStr = newStr
			}
		}
		if c.ApplicationName != "" {
			connStr, _ = addConnSetting(connStr, "application_name", c.ApplicationName)
		}
		return connStr
	}

	sslMode := c.SSLMode
	if sslMode == "" {
		sslMode = "require"
	}

	connStr = fmt.Sprintf("host=%s port=%s user=%s password=%s dbname=%s sslmode=%s",
		c.Host, c.Port, c.User, c.Password, c.Database, sslMode)

	connStr, _ = addConnSetting(connStr, "idle_in_transaction_session_timeout", "30000")
	connStr, _ = addConnSetting(connStr, "statement_timeout", "60000")
	if strings.Contains(connStr, "pooler.supabase.com") {
		if newStr, added := addConnSetting(connStr, "default_query_exec_mode", "simple_protocol"); added {
			log.Info().Msg("Added minimal prepared statement disabling for pooler connection")
			connStr = newStr
		} else {
			connStr = newStr
		}
	}
	if c.ApplicationName != "" {
		connStr, _ = addConnSetting(connStr, "application_name", c.ApplicationName)
	}

	return connStr
}

// Validate checks if the configuration is valid
func (c *Config) Validate() error {
	// If we have a DatabaseURL, that's sufficient
	if c.DatabaseURL != "" {
		return nil
	}

	// Otherwise, check individual fields
	if c.Host == "" || c.Port == "" || c.User == "" || c.Password == "" || c.Database == "" {
		if c.Host == "" && c.Port == "" && c.User == "" && c.Password == "" && c.Database == "" {
			return fmt.Errorf("database configuration required")
		}
		return fmt.Errorf("incomplete database configuration")
	}

	return nil
}

// New creates a new PostgreSQL database connection
func New(config *Config) (*DB, error) {
	// Validate required fields only if not using DATABASE_URL
	if config.DatabaseURL == "" {
		if config.Host == "" {
			return nil, fmt.Errorf("database host is required")
		}
		if config.Port == "" {
			return nil, fmt.Errorf("database port is required")
		}
		if config.User == "" {
			return nil, fmt.Errorf("database user is required")
		}
		if config.Database == "" {
			return nil, fmt.Errorf("database name is required")
		}
	}

	// Set defaults for optional fields
	if config.SSLMode == "" {
		config.SSLMode = "disable"
	}
	if config.MaxIdleConns == 0 {
		// Environment-based idle connection limits (~30% of max open)
		switch os.Getenv("APP_ENV") {
		case "production":
			config.MaxIdleConns = 20
		case "staging":
			config.MaxIdleConns = 4
		default:
			config.MaxIdleConns = 1
		}
	}
	if config.MaxOpenConns == 0 {
		// Environment-based connection limits to prevent pool exhaustion
		switch os.Getenv("APP_ENV") {
		case "production":
			config.MaxOpenConns = 70
		case "staging":
			config.MaxOpenConns = 10
		default:
			config.MaxOpenConns = 3
		}
	}
	if config.MaxLifetime == 0 {
		config.MaxLifetime = 5 * time.Minute // Shorter lifetime for pooler compatibility
	}

	if config.ApplicationName == "" {
		config.ApplicationName = determineApplicationName()
	}

	connStr := config.ConnectionString()

	log.Info().Msg("Opening PostgreSQL connection")

	client, err := sql.Open("pgx", connStr)
	if err != nil {
		return nil, fmt.Errorf("failed to connect to PostgreSQL: %w", err)
	}

	// Configure connection pool
	client.SetMaxOpenConns(config.MaxOpenConns)
	client.SetMaxIdleConns(config.MaxIdleConns)
	client.SetConnMaxLifetime(config.MaxLifetime)
	client.SetConnMaxIdleTime(2 * time.Minute) // Close idle connections after 2 minutes

	// Test connection
	if err := client.Ping(); err != nil {
		return nil, fmt.Errorf("failed to ping PostgreSQL: %w", err)
	}

	cleanupAppConnections(context.Background(), client, config.ApplicationName)

	// Schema is managed by Supabase migrations - no setup required

	// Create the cache
	dbCache := cache.NewInMemoryCache()

	return &DB{client: client, config: config, Cache: dbCache}, nil
}

// InitFromURLWithSuffix creates a PostgreSQL connection using the provided URL and optional
// application name suffix. It applies the same environment-based pooling limits as InitFromEnv.
func InitFromURLWithSuffix(databaseURL string, appEnv string, appNameSuffix string) (*DB, error) {
	trimmed := strings.TrimSpace(databaseURL)
	if trimmed == "" {
		return nil, fmt.Errorf("database url cannot be empty")
	}

	maxOpen, maxIdle := poolLimitsForEnv(appEnv)
	appName := determineApplicationName()
	if suffix := sanitiseAppName(appNameSuffix); suffix != "" {
		if appName != "" {
			appName = trimAppName(fmt.Sprintf("%s:%s", appName, suffix))
		} else {
			appName = trimAppName(suffix)
		}
	}

	config := &Config{
		DatabaseURL:     trimmed,
		MaxIdleConns:    maxIdle,
		MaxOpenConns:    maxOpen,
		MaxLifetime:     5 * time.Minute,
		ApplicationName: appName,
	}

	db, err := New(config)
	if err != nil {
		return nil, err
	}

	return db, nil
}

// InitFromEnv creates a PostgreSQL connection using environment variables
func InitFromEnv() (*DB, error) {
	// If DATABASE_URL is provided, use it with default config
	// Trim whitespace as it causes pgx to ignore the URL and fall back to Unix socket
	if url := strings.TrimSpace(os.Getenv("DATABASE_URL")); url != "" {
		// Optimise connection limits based on environment
		maxOpen, maxIdle := poolLimitsForEnv(os.Getenv("APP_ENV"))

		appName := determineApplicationName()

		config := &Config{
			DatabaseURL:     url,
			MaxIdleConns:    maxIdle,
			MaxOpenConns:    maxOpen,
			MaxLifetime:     5 * time.Minute, // Shorter lifetime for pooler compatibility
			ApplicationName: appName,
		}

		url, _ = addConnSetting(url, "statement_timeout", "60000")
		url, _ = addConnSetting(url, "idle_in_transaction_session_timeout", "30000")

		if strings.Contains(url, "pooler.supabase.com") {
			if newStr, added := addConnSetting(url, "default_query_exec_mode", "simple_protocol"); added {
				log.Info().Msg("Added minimal prepared statement disabling for pooler connection")
				url = newStr
			} else {
				url = newStr
			}

			if newStr, added := addConnSetting(url, "pgbouncer", "true"); added {
				log.Info().Msg("Enabled transaction pooling mode (pgbouncer=true)")
				url = newStr
			} else {
				url = newStr
			}
		}

		if appName != "" {
			url, _ = addConnSetting(url, "application_name", appName)
		}

		// Persist the augmented URL back to config for consistency
		config.DatabaseURL = url

		log.Info().Str("connection_url", url).Msg("Opening PostgreSQL connection via DATABASE_URL")

		client, err := sql.Open("pgx", url)
		if err != nil {
			return nil, fmt.Errorf("failed to connect to PostgreSQL via DATABASE_URL: %w", err)
		}

		// Configure connection pool using the same settings
		client.SetMaxOpenConns(config.MaxOpenConns)
		client.SetMaxIdleConns(config.MaxIdleConns)
		client.SetConnMaxLifetime(config.MaxLifetime)
		client.SetConnMaxIdleTime(2 * time.Minute) // Close idle connections after 2 minutes

		// Verify connection
		if err := client.Ping(); err != nil {
			return nil, fmt.Errorf("failed to ping PostgreSQL via DATABASE_URL: %w", err)
		}

		cleanupAppConnections(context.Background(), client, config.ApplicationName)

		// Schema is managed by Supabase migrations - no setup required

		// Create the cache
		dbCache := cache.NewInMemoryCache()

		return &DB{client: client, config: config, Cache: dbCache}, nil
	}

	// Fallback to individual environment variables
	maxOpen, maxIdle := poolLimitsForEnv(os.Getenv("APP_ENV"))

	appName := determineApplicationName()

	config := &Config{
		Host:            os.Getenv("POSTGRES_HOST"),
		Port:            os.Getenv("POSTGRES_PORT"),
		User:            os.Getenv("POSTGRES_USER"),
		Password:        os.Getenv("POSTGRES_PASSWORD"),
		Database:        os.Getenv("POSTGRES_DB"),
		SSLMode:         os.Getenv("POSTGRES_SSL_MODE"),
		MaxIdleConns:    maxIdle,
		MaxOpenConns:    maxOpen,
		MaxLifetime:     5 * time.Minute,
		ApplicationName: appName,
	}

	// Use defaults if not set
	if config.Host == "" {
		config.Host = "localhost"
	}
	if config.Port == "" {
		config.Port = "5432"
	}
	if config.User == "" {
		config.User = "postgres"
	}
	if config.Database == "" {
		config.Database = "blue_banded_bee"
	}

	// Create the database connection
	db, err := New(config)
	if err != nil {
		return nil, err
	}

	return db, nil
}

// createCoreTables creates all core database tables

// Close closes the database connection
func (db *DB) Close() error {
	return db.client.Close()
}

// GetDB returns the underlying database connection
func (db *DB) GetDB() *sql.DB {
	return db.client
}

// GetDomainNameByID retrieves a single domain name by ID
func (db *DB) GetDomainNameByID(ctx context.Context, domainID int) (string, error) {
	var domainName string
	err := db.client.QueryRowContext(ctx, `SELECT name FROM domains WHERE id = $1`, domainID).Scan(&domainName)
	if err != nil {
		if err == sql.ErrNoRows {
			return "", fmt.Errorf("domain not found")
		}
		return "", fmt.Errorf("failed to get domain name: %w", err)
	}
	return domainName, nil
}

// GetDomainNames retrieves domain names for multiple domain IDs in a single query
// Returns a map of domainID -> domainName
func (db *DB) GetDomainNames(ctx context.Context, domainIDs []int) (map[int]string, error) {
	if len(domainIDs) == 0 {
		return make(map[int]string), nil
	}

	query := `SELECT id, name FROM domains WHERE id = ANY($1)`
	rows, err := db.client.QueryContext(ctx, query, domainIDs)
	if err != nil {
		return nil, fmt.Errorf("failed to query domain names: %w", err)
	}
	defer rows.Close()

	domainNames := make(map[int]string)
	for rows.Next() {
		var domainID int
		var domainName string
		if err := rows.Scan(&domainID, &domainName); err != nil {
			log.Warn().Err(err).Msg("Failed to scan domain row")
			continue
		}
		domainNames[domainID] = domainName
	}

	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("error iterating domain rows: %w", err)
	}

	return domainNames, nil
}

// UpdateDomainTechnologies updates the detected technologies for a domain.
// Called after first successful task crawl in a job to store tech detection results.
func (db *DB) UpdateDomainTechnologies(ctx context.Context, domainID int, technologies, headers []byte, htmlPath string) error {
	query := `
		UPDATE domains
		SET technologies = $2,
			tech_headers = $3,
			tech_html_path = $4,
			tech_detected_at = NOW()
		WHERE id = $1`

	_, err := db.client.ExecContext(ctx, query, domainID, technologies, headers, htmlPath)
	if err != nil {
		return fmt.Errorf("failed to update domain technologies: %w", err)
	}

	return nil
}

// ResetDataOnly clears all data from tables but preserves the schema.
// This is the safe option for clearing test data without triggering schema changes.
func (db *DB) ResetDataOnly() error {
	startTime := time.Now()
	log.Warn().Msg("=== DATA-ONLY RESET STARTED ===")
	log.Warn().Msg("Clearing all data from database tables (schema preserved)")

	// Use TRUNCATE instead of DELETE - it's atomic, faster, and handles concurrent access better
	// TRUNCATE automatically handles foreign key constraints with CASCADE
	tables := []string{"tasks", "jobs", "job_share_links", "schedulers", "pages", "domains"}
	totalRowsDeleted := int64(0)

	log.Info().Msg("Step 1/2: Truncating all data from tables")
	for i, table := range tables {
		tableStart := time.Now()
		log.Info().
			Str("table", table).
			Int("table_num", i+1).
			Int("total_tables", len(tables)).
			Msg("Truncating table data")

		// Get row count before truncate (warn if it fails but keep going)
		var rowCount int64
		if err := db.client.QueryRow(fmt.Sprintf(`SELECT COUNT(*) FROM %s`, table)).Scan(&rowCount); err != nil {
			log.Warn().Err(err).Str("table", table).Msg("Failed to count rows before truncate")
		}

		// TRUNCATE is atomic and releases all locks immediately
		_, err := db.client.Exec(fmt.Sprintf(`TRUNCATE TABLE %s CASCADE`, table))
		if err != nil {
			log.Error().
				Err(err).
				Str("table", table).
				Dur("elapsed", time.Since(tableStart)).
				Msg("FAILED to truncate table - reset aborted")
			return fmt.Errorf("failed to truncate table %s: %w", table, err)
		}

		totalRowsDeleted += rowCount
		log.Info().
			Str("table", table).
			Int64("rows_deleted", rowCount).
			Dur("duration", time.Since(tableStart)).
			Msg("Truncated table data successfully")
	}

	log.Info().
		Int64("total_rows_deleted", totalRowsDeleted).
		Dur("step_duration", time.Since(startTime)).
		Msg("Step 1/2 completed: All table data cleared")

	// Reset sequences to start from 1 again
	sequenceStart := time.Now()
	log.Info().Msg("Step 2/2: Resetting sequences")
	sequences := []struct {
		name  string
		table string
	}{
		{"domains_id_seq", "domains"},
		{"pages_id_seq", "pages"},
	}

	sequencesReset := 0
	for _, seq := range sequences {
		_, err := db.client.Exec(fmt.Sprintf(`ALTER SEQUENCE %s RESTART WITH 1`, seq.name))
		if err != nil {
			log.Warn().
				Err(err).
				Str("sequence", seq.name).
				Msg("Failed to reset sequence (may not exist)")
		} else {
			sequencesReset++
			log.Info().
				Str("sequence", seq.name).
				Msg("Reset sequence to 1")
		}
	}

	log.Info().
		Int("sequences_reset", sequencesReset).
		Int("sequences_total", len(sequences)).
		Dur("step_duration", time.Since(sequenceStart)).
		Msg("Step 2/2 completed: Sequences reset")

	totalDuration := time.Since(startTime)
	log.Warn().
		Dur("total_duration", totalDuration).
		Int64("total_rows_deleted", totalRowsDeleted).
		Msg("=== DATA-ONLY RESET COMPLETED SUCCESSFULLY ===")
	log.Warn().Msg("Schema preserved - no migrations affected")

	return nil
}

// RecalculateJobStats recalculates all statistics for a job based on actual task records
func (db *DB) RecalculateJobStats(ctx context.Context, jobID string) error {
	_, err := db.client.ExecContext(ctx, `SELECT recalculate_job_stats($1)`, jobID)
	if err != nil {
		return fmt.Errorf("failed to recalculate job stats: %w", err)
	}
	return nil
}

// Serialise converts data to JSON string representation.
// It is named with British English spelling for consistency.
func Serialise(v interface{}) string {
	data, err := json.Marshal(v)
	if err != nil {
		log.Error().Err(err).Msg("Failed to serialise data")
		return "{}"
	}
	return string(data)
}
